\newcommand{\blockSpaceOne}{\vspace{1.3cm}}
\newcommand{\interBlockSpaceOne}{\vspace{1.5cm}}
\newcommand{\blockSpaceTwo}{\vspace{1.3cm}}
\newcommand{\interBlockSpaceTwo}{\vspace{.95cm}}
\newcommand{\secondBlockImSpace}{\vspace{.25cm}}
\newcommand{\thirdBlockImSpace}{\vspace{1.125cm}}

\begin{frame} % The whole poster is enclosed in one beamer frame
	\vspace{-.5cm}
	\begin{columns}
		\begin{column}{.005\textwidth}\end{column}

		
		\begin{column}{0.99\textwidth}
			\begin{columns}[t]

				\begin{column}{.01\textwidth}\end{column}

				\begin{column}{0.32\textwidth}


					\begin{block}{\large 1 The BrainScaleS system}
					\blockSpaceOne


					\justifying
					\begin{adjustwidth}{1.cm}{1.cm}
					 On a single module of the \textbf{BrainScaleS \cite{schemmel2010wafer} analog neuromorphic hardware} (Fig-A) the physical model of \textbf{200k neurons and 40 million synapses} is implemented using CMOS technology.
					 The system follows the principle of \textbf{physical modeling}: it uses the dynamics of the underlying substrate to implement computation.
					 
					\end{adjustwidth}

					\vspace{1.cm}
					\begin{center}
						\includegraphics[width=\textwidth]{figHWfull}
					\end{center}

					\begin{adjustwidth}{1cm}{1cm}
					As such it can emulate networks of spiking neurons with \boldmath{$10^4$}\textbf{-fold speed-up} compared to biological real-time, but suffers from the variability of the parameters (Fig-B-C).
					Hence, we require robust network dynamics and learning rules.

					\end{adjustwidth}

					\blockSpaceOne
					\end{block}

					\interBlockSpaceOne

					\begin{block}{\large 2 Sampling as robust coding}
					\blockSpaceOne

					\begin{adjustwidth}{1.cm}{1.cm}
					\justifying
					According to the \textbf{neural sampling hypothesis} \cite{fiser2010statistically} certain cortical areas implement \textbf{sampling based probabilistic inference}.
					These models are of particular interest for physical model systems as the brain faces similar challenges.

					\vspace{.5cm}
					\begin{center}
						\includegraphics[width=.9\textwidth]{figTHfull}
					\end{center}
					\vspace{.5cm}

					In the \textbf{LIF sampling} framework \cite{petrovici2016stochastic} a single neuron describes a binary random variable based on its spiking behavior (Fig-A-B).
					The network approximately samples from a Boltzmann distribution over binary random variables:
					\begin{align*}
					p(z) &= \frac{1}{Z} \exp \left ( \frac{1}{2} \sum_{ij} W_{ij} z_i z_j + \sum_{i} b_i z_i  \right) \\
					Z &= \sum_{z\in\{0,1\}^N} \exp \left ( \frac{1}{2} \sum_{ij} W_{ij} z_i z_j + \sum_{i} b_i z_i  \right)
					\end{align*}
					\end{adjustwidth}
					For practical applications we use a \textbf{hierarchical sampling network} (Fig-C) inspired by restricted Boltzmann machines \cite{hinton1984boltzmann}.



					\blockSpaceOne
					\end{block}





				\end{column}

				\begin{column}{.01\textwidth}\end{column}

				\begin{column}{0.32\textwidth}


					\begin{block}{\large 3 From theory to hardware}
					\blockSpaceOne

					\begin{adjustwidth}{1.cm}{1.cm}
					\justifying
					We adapted the LIF sampling theory to the characteristics of the hardware.
					A random inhibition-dominated \textbf{decorrelation network (DN)} provides the necessary stochasticity to the sampling network (Fig-A).
					This way we realized a fully \textbf{self-contained sampler} on the accelerated substrate.
					As a comparison we implemented the setup with external Poisson noise (Fig-B).
					\end{adjustwidth}

					\secondBlockImSpace
					\begin{center}
						\includegraphics[width=1.\textwidth]{figSetupFull}
					\end{center}
					\secondBlockImSpace

					\begin{adjustwidth}{1.cm}{1.cm}
					\justifying
					The hardware constraints lead to distortions in the activation function from the ideal sigmoid shape (Fig-C-E); but this can be accounted for by in-the-loop training.
					\end{adjustwidth}

					\blockSpaceOne
					\end{block}

					\interBlockSpaceOne

					\begin{block}{\large 4 In-the-loop training}
					\blockSpaceOne

					\begin{adjustwidth}{1.cm}{1.cm}
					\justifying
					We trained a 5 neuron network to \textbf{sample from a target probability distribution}.
					We used the \textbf{wake-sleep algorithm} \cite{ackley1987learning}:
					\secondBlockImSpace
					\begin{equation}\label{eq:wake_sleep}
						\begin{split}
						\Delta b_i &= \eta(\langle z_i \rangle_{data} - \langle z_i \rangle_{model}) \\
						\Delta W_{ij} &= \eta (\langle z_i z_j \rangle_{data} - \langle z_i z_j\rangle_{model})
						\end{split}
					\end{equation}
					\secondBlockImSpace
					where the data phase is given by the target distribution.
					We trained the networks in an \textbf{in-the-loop} manner: Parameter updates are calculated on the host computer with \cref{eq:wake_sleep} based on the spike times measured on hardware.
					\end{adjustwidth}
					\secondBlockImSpace
					\begin{center}
						\includegraphics[width=1.\textwidth]{figDistr}
					\end{center}
					\secondBlockImSpace

					\begin{adjustwidth}{1.cm}{1.cm}
					\justify
					
					The \textbf{training reduced the Kullbeck-Leibler Divergence (DKL)} between the sampled and the target distribution (Fig-A-F).
					Due to the acceleration of the hardware \textbf{the full training scheme (including overhead) is two orders of magnitude faster than biological real-time}.
					\end{adjustwidth}

					\blockSpaceOne
					\end{block}





				\end{column}

				\begin{column}{.01\textwidth}\end{column}

				\begin{column}{0.32\textwidth}

					\begin{block}{\large 5 Application to handwritten digits}
					\blockSpaceTwo

					\begin{center}
						\includegraphics[width=1.\textwidth]{figInference}
					\end{center}
					\thirdBlockImSpace

					\begin{adjustwidth}{1.cm}{1.cm}
					\justify
					 Using the LIF sampling framework we implemented a \textbf{restricted Boltzmann machine} (RBM) \cite{hinton1984boltzmann} on the BrainScaleS System.
					 We evaluate the model on a reduced version of the MNIST dataset \cite{lecun1998gradient}.
					 The original pictures were binarized, reduced to $12\times12$ pixels and the digits 0,1,4 and 7 were selected (Fig-A).
					\end{adjustwidth}

					\thirdBlockImSpace
					\begin{center}
						\includegraphics[width=1.\textwidth]{figPatternComp}
					\end{center}
					\thirdBlockImSpace


					\begin{adjustwidth}{1.cm}{1.cm}
					\justify
					We use an on the host computer pretrained RBM and perform \textit{in-the-loop training } to compensate for the model and substrate imperfections.
					The \textbf{classification} rate recovers software level performance after $O(10)$ training steps (Fig-B).
					The implemented model is able to \textbf{complete partially occluded images} while predicting the label correctly (Fig-C-F).
					Finally it is able to \textbf{generate recognizable images} if the respective label is clamped (Fig-G).

					\end{adjustwidth}
					\thirdBlockImSpace
					\begin{center}
						\includegraphics[width=1.\textwidth]{figTsne}
					\end{center}

					
					\blockSpaceTwo
					\end{block}


					\interBlockSpaceTwo




				\end{column}

				\begin{column}{.005\textwidth}\end{column}


			\end{columns}



		\end{column}
		\begin{column}{.005\textwidth}\end{column}
	\end{columns}

	\vspace{0cm}

	\begin{columns}[t]
		\begin{column}{.01\textwidth}\end{column}

		\begin{column}{.98\textwidth}
			\begin{block}{References}
			 \begin{minipage}{0.79\linewidth}
								\tiny
								\bibliographystyle{ieeetr}
								\bibliography{bib}
			 \end{minipage}
			 \begin{minipage}{.09\linewidth}
				\includegraphics[width=1\textwidth,right]{QRguidebook}
			 \end{minipage}
			 \begin{minipage}{.09\linewidth}
				\includegraphics[width=1\textwidth,right]{QRpubl}
			 \end{minipage}

			\end{block}
		\end{column}

		\begin{column}{.01\textwidth}\end{column}
	\end{columns}

\end{frame} % End of the enclosing frame
